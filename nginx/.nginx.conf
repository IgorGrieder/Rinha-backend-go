# Sets the number of worker processes to the number of CPU cores.
# This ensures optimal performance by utilizing all available cores.
worker_processes auto;

# Increases the maximum number of file descriptors (open sockets)
# available to each worker process, which is crucial for handling
# a large number of concurrent connections.
worker_rlimit_nofile 65535;

events {
    # Sets the maximum number of simultaneous connections that can be handled
    # by each worker process.
    worker_connections 4096;

    # Specifies the event-notification method for a Linux system.
    # `epoll` is the most efficient method for high-concurrency servers.
    use epoll;

    # Tells NGINX to accept as many new connections as possible from the queue
    # at a time, instead of one-by-one, which improves performance.
    multi_accept on;
}

http {
    # Enables the `sendfile()` system call to copy data directly between file descriptors,
    # which bypasses user space and significantly improves performance for file transfers.
    sendfile on;

    # TCP optimizations for reducing the number of network packets and latency.
    tcp_nopush on;
    tcp_nodelay on;

    # Sets the timeout for client keep-alive connections.
    keepalive_timeout 30;

    # Sets the maximum number of requests that can be served over a single keep-alive connection.
    keepalive_requests 1000;
    
    # Hides the NGINX version number in error pages and HTTP headers for security.
    server_tokens off;

    # Disables the access log.
    access_log off;

    # Directs error logs to standard error, which is ideal for Docker logs.
    error_log /dev/stderr warn;
    
    # Defines a group of backend servers for load balancing.
    upstream go_backend {
        # Load balancing algorithm: sends requests to the server with the fewest active connections.
        least_conn;
        
        # Defines the backend servers using their Docker service names and ports.
        # NGINX resolves these hostnames within the Docker network.
        # Note: Both backend services listen on the same port (8080) inside their containers.
        server backend-1:8080 max_fails=3 fail_timeout=30s;
        server backend-2:8080 max_fails=3 fail_timeout=30s;
        
        # Enables keep-alive connections to the upstream servers for performance.
        keepalive 32;
        keepalive_requests 1000;
        keepalive_timeout 60s;
    }
    
    # Defines the main NGINX server that listens for incoming client requests.
    server {
        # NGINX listens on port 9999.
        listen 9999;
        
        # Sets a limit for the maximum size of a client request body.
        client_max_body_size 1M;
        
        # Timeouts to prevent slow-client attacks.
        client_body_timeout 10s;
        client_header_timeout 10s;
        
        # Defines the root location for the server.
        location / {
            # Proxies requests to the `go_backend` upstream group.
            proxy_pass http://go_backend;
            
            # Forwards the original host, client IP, and other headers to the backend.
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Sets connection, send, and read timeouts for the proxy process.
            proxy_connect_timeout 3s;
            proxy_send_timeout 8s;
            proxy_read_timeout 8s;
            
            # Specifies the HTTP protocol version for proxying.
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            
            # Disables buffering between NGINX and the backend to reduce latency.
            proxy_buffering off;
            proxy_request_buffering off;
        }
    }
}
